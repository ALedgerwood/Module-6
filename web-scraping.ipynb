{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Mining and Applied NLP (44-620)\n",
    "\n",
    "## Web Scraping and NLP with Requests, BeautifulSoup, and spaCy\n",
    "\n",
    "### Student Name: Alexandra Ledgerwood\n",
    "Github Repo: https://github.com/ALedgerwood/Module-6\n",
    "\n",
    "Perform the tasks described in the Markdown cells below.  When you have completed the assignment make sure your code cells have all been run (and have output beneath them) and ensure you have committed and pushed ALL of your changes to your assignment repository.\n",
    "\n",
    "Every question that requires you to write code will have a code cell underneath it; you may either write your entire solution in that cell or write it in a python file (`.py`), then import and run the appropriate code to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code that extracts the article html from https://web.archive.org/web/20210327165005/https://hackaday.com/2021/03/22/how-laser-headlights-work/ and dumps it to a .pkl (or other appropriate file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "### extract article html from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "text/html; charset=UTF-8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://web.archive.org/web/20210327165005/https://hackaday.com/2021/03/22/how-laser-headlights-work/')\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.headers['content-type'])\n",
    "# Uncomment next line to print the full HTML text;  it's long so when done, recomment\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# parser = 'html5lib'\n",
    "parser = 'html.parser'\n",
    "\n",
    "soup = BeautifulSoup(response.text, parser)\n",
    "# Uncomment next lines to explore full page contents; it's long so when done, recomment\n",
    "# print(soup)\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 header: <h1 class=\"site-title\">\n",
      "<a href=\"https://web.archive.org/web/20210327165005/https://hackaday.com/\" rel=\"home\">Hackaday</a>\n",
      "</h1>\n",
      "h1 header: <h1 class=\"entry-title\" itemprop=\"name\">How Laser Headlights Work</h1>\n",
      "h1 header: <h1 class=\"screen-reader-text\">Post navigation</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Search</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Never miss a hack</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Subscribe</h1>\n",
      "h1 header: <h1 class=\"widget-title\">If you missed it</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Our Columns</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Search</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Never miss a hack</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Subscribe</h1>\n",
      "h1 header: <h1 class=\"widget-title\">If you missed it</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Categories</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Our Columns</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Recent comments</h1>\n",
      "h1 header: <h1 class=\"widget-title\">Now on Hackaday.io</h1>\n",
      "h1 header: <h1 class=\"footer-widget-title\">Never miss a hack</h1>\n",
      "h1 header: <h1 class=\"footer-widget-title\">Subscribe to Newsletter</h1>\n"
     ]
    }
   ],
   "source": [
    "for header in soup.findAll('h1'):\n",
    "    print('h1 header:', header)\n",
    "    #print('h1 text:', header.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article HTML saved to article_html.pkl\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pickle\n",
    "\n",
    "def extract_article_html(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Failed to fetch the webpage\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://web.archive.org/web/20210327165005/https://hackaday.com/2021/03/22/how-laser-headlights-work/\"\n",
    "    article_html = extract_article_html(url)\n",
    "\n",
    "    if article_html:\n",
    "        output_filename = \"article_html.pkl\"\n",
    "        with open(output_filename, \"wb\") as f:\n",
    "            pickle.dump(article_html, f)\n",
    "        print(f\"Article HTML saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read in your article's html source from the file you created in question 1 and print it's text (use `.get_text()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "### Get the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Python Will Soon Support Switch Statements\n",
      "\n",
      "\n",
      "                112 Comments            \n",
      "\n",
      "by:\n",
      "Adam Zeloof\n",
      "\n",
      "\n",
      "\n",
      "April 2, 2021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Rejoice! Gone are the long chains of if…else statements, because switch statements will soon be here — sort of. What the Python gods are actually giving us are match statements. match statements are awfully similar to switch statements, but have a few really cool and unique features, which I’ll attempt to illustrate below.\n",
      "\n",
      "Flip The Switch\n",
      "A switch statement is often used in place of an if…else ladder. Here’s a quick example of the same logic in C, first executed with an if statement, and then with a switch statement:\n",
      "\n",
      "Essentially, a switch statement takes a variable and tests it for equality against a number of different cases. If none of the cases match, then the default case is invoked. Notice in the example that each case is terminated by a break. This protects against more than one case matching (or allows for cascading), as the cases are checked in the order in which they are listed. Once a case is completed, break is called and the switch statement exits.\n",
      "A Match Made In Heaven\n",
      "\n",
      "You can think of match statements as “Switch 2.0”. Before we get into the nitty-gritty here, if all you want is switch in Python then you’re in luck, because they can be used in the same way. Here’s a similar example to what we looked at earlier, this time using match in Python.\n",
      "There are a few differences to note right off the bat. First, there are no break statements. The developers were concerned about confusion if a break statement were called inside a match statement inside a loop — what breaks then, the loop or the match? Here, the first case that is satisfied is executed, and the statement returns. You’ll also notice that rather than default, we have case _, which behaves in the same way.\n",
      "The Power of Pattern Matching\n",
      "So, we’ve got a switch statement with slightly different syntax, right? Not quite. The name match was used for a reason — what’s actually going on here is something called Pattern Matching. To illustrate what that is, let’s look at a more exciting example, right out of the feature proposal to add the keyword in question to Python:\n",
      "\n",
      "Wow! We just took an object, checked its type, checked it’s shape, and instantiated a new object without any indexing, or even a len() call. It also works on any type, unlike the classic switch which only works on integral values. In case this wasn’t cool enough for you, patterns can be combined. Again, from the feature proposal:\n",
      "\n",
      "Okay, okay — one more example. This is where the match statement gets really powerful. Patterns themselves can include comparisons, known as guards. This lets you filter values within each case statement:\n",
      "\n",
      "Sold! When Can I Try?\n",
      "We’ll get our hands on this magical new command in Python 3.10, slated for a full release on October 4th, 2021. For the adventurous, an alpha version (Python 3.10.0a6) is available for download today. It might be worth spending some time getting acquainted with the pattern matching, like understanding the difference between matching literal values and matching variables.\n",
      "So why doesn’t every language have match statements? They’re clearly better than switch statements!\n",
      "That’s what I said at least, and my girlfriend Sara was quick to raise her eyebrows and explain that there’s a huge performance overhead involved. The switch statement in C is relatively simple. It compares integers to one another, executing n constant-time operations. All of the power and convenience that comes with the match statement means a lot is going on in the background, which in turn slows down the code execution — an incredibly Pythonic tradeoff to make.\n",
      "I find an efficiency hit a small price to pay for such expanded functionality, but as a Mechanical Engineer my favorite languages are Matlab and Python so you probably should take my opinion here with a grain of salt.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posted in Featured, News, Slider, Software DevelopmentTagged match, python, switch \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(article_element.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent tokens (converted to lower case).  Print the common tokens with an appropriate label.  Additionally, print the tokens their frequencies (with appropriate labels). Make sure to remove things we don't care about (punctuation, stopwords, whitespace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "### Determine five most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Python, Will, Soon, Support, Switch, Statements, 112, Comments, by, :, Adam, Zeloof, April, 2, ,, 2021, Rejoice, !, Gone, are, the, long, chains, of, if, …, else, statements, ,, because, switch, statements, will, soon, be, here, —, sort, of, ., What, the, Python, gods, are, actually, giving, us, are, match, statements, ., match, statements, are, awfully, similar, to, switch, statements, ,, but, have, a, few, really, cool, and, unique, features, ,, which, I, ’ll, attempt, to, illustrate, below, ., Flip, The, Switch, A, switch, statement, is, often, used, in, place, of, an, if, …, else, ladder, ., Here, ’s, a, quick, example, of, the, same, logic, in, C, ,, first, executed, with, an, if, statement, ,, and, then, with, a, switch, statement, :, Essentially, ,, a, switch, statement, takes, a, variable, and, tests, it, for, equality, against, a, number, of, different, cases, ., If, none, of, the, cases, match, ,, then, the, default, case, is, invoked, ., Notice, in, the, example, that, each, case, is, terminated, by, a, break, ., This, protects, against, more, than, one, case, matching, (, or, allows, for, cascading, ), ,, as, the, cases, are, checked, in, the, order, in, which, they, are, listed, ., Once, a, case, is, completed, ,, break, is, called, and, the, switch, statement, exits, ., A, Match, Made, In, Heaven, You, can, think, of, match, statements, as, “, Switch, 2.0, ”, ., Before, we, get, into, the, nitty, -, gritty, here, ,, if, all, you, want, is, switch, in, Python, then, you, ’re, in, luck, ,, because, they, can, be, used, in, the, same, way, ., Here, ’s, a, similar, example, to, what, we, looked, at, earlier, ,, this, time, using, match, in, Python, ., There, are, a, few, differences, to, note, right, off, the, bat, ., First, ,, there, are, no, break, statements, ., The, developers, were, concerned, about, confusion, if, a, break, statement, were, called, inside, a, match, statement, inside, a, loop, —, what, breaks, then, ,, the, loop, or, the, match, ?, Here, ,, the, first, case, that, is, satisfied, is, executed, ,, and, the, statement, returns, ., You, ’ll, also, notice, that, rather, than, default, ,, we, have, case, _, ,, which, behaves, in, the, same, way, ., The, Power, of, Pattern, Matching, So, ,, we, ’ve, got, a, switch, statement, with, slightly, different, syntax, ,, right, ?, Not, quite, ., The, name, match, was, used, for, a, reason, —, what, ’s, actually, going, on, here, is, something, called, Pattern, Matching, ., To, illustrate, what, that, is, ,, let, ’s, look, at, a, more, exciting, example, ,, right, out, of, the, feature, proposal, to, add, the, keyword, in, question, to, Python, :, Wow, !, We, just, took, an, object, ,, checked, its, type, ,, checked, it, ’s, shape, ,, and, instantiated, a, new, object, without, any, indexing, ,, or, even, a, len, (, ), call, ., It, also, works, on, any, type, ,, unlike, the, classic, switch, which, only, works, on, integral, values, ., In, case, this, was, n’t, cool, enough, for, you, ,, patterns, can, be, combined, ., Again, ,, from, the, feature, proposal, :, Okay, ,, okay, —, one, more, example, ., This, is, where, the, match, statement, gets, really, powerful, ., Patterns, themselves, can, include, comparisons, ,, known, as, guards, ., This, lets, you, filter, values, within, each, case, statement, :, Sold, !, When, Can, I, Try, ?, We, ’ll, get, our, hands, on, this, magical, new, command, in, Python, 3.10, ,, slated, for, a, full, release, on, October, 4th, ,, 2021, ., For, the, adventurous, ,, an, alpha, version, (, Python, 3.10.0a6, ), is, available, for, download, today, ., It, might, be, worth, spending, some, time, getting, acquainted, with, the, pattern, matching, ,, like, understanding, the, difference, between, matching, literal, values, and, matching, variables, ., So, why, does, n’t, every, language, have, match, statements, ?, They, ’re, clearly, better, than, switch, statements, !, That, ’s, what, I, said, at, least, ,, and, my, girlfriend, Sara, was, quick, to, raise, her, eyebrows, and, explain, that, there, ’s, a, huge, performance, overhead, involved, ., The, switch, statement, in, C, is, relatively, simple, ., It, compares, integers, to, one, another, ,, executing, n, constant, -, time, operations, ., All, of, the, power, and, convenience, that, comes, with, the, match, statement, means, a, lot, is, going, on, in, the, background, ,, which, in, turn, slows, down, the, code, execution, —, an, incredibly, Pythonic, tradeoff, to, make, ., I, find, an, efficiency, hit, a, small, price, to, pay, for, such, expanded, functionality, ,, but, as, a, Mechanical, Engineer, my, favorite, languages, are, Matlab, and, Python, so, you, probably, should, take, my, opinion, here, with, a, grain, of, salt, ., Posted, in, Featured, ,, News, ,, Slider, ,, Software, DevelopmentTagged, match, ,, python, ,, switch]\n"
     ]
    }
   ],
   "source": [
    "non_ws_tokens = []\n",
    "for token in doc:\n",
    "    if not token.is_space:\n",
    "        non_ws_tokens.append(token)\n",
    "print(non_ws_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most common tokens are: [('switch', 15), ('match', 13), ('statement', 13), ('statements', 10), ('python', 9)]\n",
      "{'statement', 'python', 'statements', 'switch', 'match'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "doc = nlp(article_element.get_text())\n",
    "\n",
    "non_ws_tokens = []\n",
    "for token in doc:\n",
    "    if not token.is_space:\n",
    "        non_ws_tokens.append(token)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def we_care_about(token):\n",
    "    return not (token.is_space or token.is_punct or token.is_stop)\n",
    "\n",
    "interesting_tokens = [token.text.lower() for token in doc if we_care_about(token)]\n",
    "word_freq = Counter(map(str,interesting_tokens))\n",
    "print(f'The 5 most common tokens are: {word_freq.most_common(5)}')\n",
    "\n",
    "top_five_tokens = set()\n",
    "for token, freq in word_freq.most_common(5):\n",
    "    top_five_tokens.add(token)\n",
    "\n",
    "print(top_five_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent lemmas (converted to lower case).  Print the common lemmas with an appropriate label.  Additionally, print the lemmas with their frequencies (with appropriate labels). Make sure to remove things we don't care about (punctuation, stopwords, whitespace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question Four\n",
    "### Five most common lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most common lemmas are: [('statement', 23), ('switch', 15), ('match', 15), ('case', 11), ('python', 9)]\n",
      "{'statement', 'python', 'case', 'switch', 'match'}\n"
     ]
    }
   ],
   "source": [
    "# dealing with words that have the same base word like headlight and headlights in this case\n",
    "interesting_lemmas = [token.lemma_.lower() for token in doc if we_care_about(token)]\n",
    "lemma_freq = Counter(interesting_lemmas)\n",
    "\n",
    "print(f'The 5 most common lemmas are: {lemma_freq.most_common(5)}')\n",
    "\n",
    "top_five_lemmas = set()\n",
    "for lemma, freq in lemma_freq.most_common(5):\n",
    "    top_five_lemmas.add(lemma)\n",
    "\n",
    "print(top_five_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define the following methods:\n",
    "    * `score_sentence_by_token(sentence, interesting_token)` that takes a sentence and a list of interesting token and returns the number of times that any of the interesting words appear in the sentence divided by the number of words in the sentence\n",
    "    * `score_sentence_by_lemma(sentence, interesting_lemmas)` that takes a sentence and a list of interesting lemmas and returns the number of times that any of the interesting lemmas appear in the sentence divided by the number of words in the sentence\n",
    "    \n",
    "You may find some of the code from the in class notes useful; feel free to use methods (rewrite them in this cell as well).  Test them by showing the score of the first sentence in your article using the frequent tokens and frequent lemmas identified in question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score_sentence_by_token \n",
    "import spacy\n",
    "import string\n",
    "\n",
    "# find the total words in a sentence \n",
    "def count_words_using_split(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    words = [word for word in words if word.strip(string.punctuation)]\n",
    "    return len(words)\n",
    "\n",
    "def score_sentence_by_token(sentence, interesting_tokens):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sentence)\n",
    "    interesting_token_count = sum([1 for token in doc if token.text.lower() in interesting_tokens])\n",
    "\n",
    "    score = interesting_token_count / count_words_using_split(sentence) if count_words_using_split(sentence) > 0 else 0.0\n",
    "\n",
    "    return score\n",
    "\n",
    "sentence1 = 'When we think about the onward march of automotive technology, headlights aren’t usually the first thing that come to mind.'\n",
    "\n",
    "score_sentence_by_token(sentence1, top_five_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score sentence by lemma\n",
    "\n",
    "import spacy\n",
    "\n",
    "def score_sentence_by_lemma(sentence, interesting_lemmas):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sentence)\n",
    "    lemmas = [token.lemma_.lower() for token in doc]\n",
    "    interesting_lemma_count = sum([1 for lemma in lemmas if lemma in interesting_lemmas])\n",
    "\n",
    "    score = interesting_lemma_count / count_words_using_split(sentence) if count_words_using_split(sentence) > 0 else 0.0\n",
    "\n",
    "    return score\n",
    "\n",
    "sentence1 = 'When we think about the onward march of automotive technology, headlights aren’t usually the first thing that come to mind.'\n",
    "\n",
    "score_sentence_by_lemma(sentence1, top_five_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Make a list containing the scores (using tokens) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores. From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Six\n",
    "### histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_sentences(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "    return sentences\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_filename = \"article_html.pkl\"\n",
    "    with open(input_filename, \"rb\") as f:\n",
    "        article_html = pickle.load(f)\n",
    "\n",
    "    article_element = soup.find('article')\n",
    "\n",
    "    article_text = article_element.get_text()\n",
    "    sentences = extract_sentences(article_text)\n",
    "    scores_by_tokens = []\n",
    "    interesting_tokens = top_five_tokens\n",
    "\n",
    "    for sentence in sentences:\n",
    "        score = score_sentence_by_token(sentence, interesting_tokens)\n",
    "        scores_by_tokens.append(score)\n",
    "\n",
    "    plt.hist(scores_by_tokens, bins=20, edgecolor='blue')\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.ylabel(\"Frequencey\")\n",
    "    plt.title(\"Distribution of Token Scores of each Sentence\")\n",
    "    plt.show()\n",
    "    \n",
    "# the most common is .00 to .17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make a list containing the scores (using lemmas) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores.  From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Which tokens and lexems would be ommitted from the lists generated in questions 3 and 4 if we only wanted to consider nouns as interesting words?  How might we change the code to only consider nouns? Put your answer in this Markdown cell (you can edit it by double clicking it)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
